---
title: "Week 5"
subtitle: "Two-Way ANOVA & linear model diagnostics"
editor:
  mode: source
format:
  revealjs: 
    output-file: w4-slides.html
    theme: ["simple", "slide_styles/slide-styles.scss"]
    smaller: true
    # navigation-mode: vertical
    slide-number: c/t
    chalkboard: 
      buttons: true
    preview-links: auto
    auto-stretch: false
    transition: fade
    transition-speed: slow
    scrollable: true
    logo: /media/5126-header.png
    css: ["default", "slide_styles/slide-styles.css", "slide_styles/slide-styles.scss"]
---

# What we'll cover today

## More tools to detect differences among samples

. . .

::: box-1-list
[{{< fa chart-simple >}}]{.margin-1} Two-Way ANOVA
:::

. . .

::: box-1-list
[{{< fa wrench >}}]{.margin-1} Linear model diagnostics
:::

. . . 

But first...

## A quiz!
**A quiz - what is it? It's a small assessment of knowledge, but that's not important right now.**
![](https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExcHN0OHdiN2I5Y2d3MjB3NXFjOTI3dm90YnAwODBmcWc0ZGRhZGU0ayZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/l4FATJpd4LWgeruTK/giphy.gif){width="1000" fig-align="center"}

## Let's check our ANOVA memory from last week...

We've learned a few ways to assess the differences between samples of data, so far mostly through comparing the *expected* values, or means. These questions will address the concepts we've discussed so far. 

## 
1. Assume we have 3 independent samples of plants grown in different fertilizer regimes and we want to compare their total height after 30 days. Given the choice between conducting and ANOVA and three independent, two-sample t-tests, which would you choose and why?

. . . 

2. All this talk of Z-tests, one-sample t-tests, two-sample t-tests, and dependent and independent t-tests is making my head spin! Help me! Why do we use t-tests rather than z-tests most of the time? What's the difference between dependent and independent two-sample t-tests?

. . . 

:::::: columns
::: {.column width="50%"}
3. Look! I did an ANOVA! What the *!&$ does it mean?! Give me a 30-second elevator pitch about what this particular `summary()` output tells us.
:::

::: {.column width="50%"}
```
Call:
lm(formula = size_cm ~ trt, data = w2.fact.df)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.4641 -2.1500 -0.1284  1.3719  5.5777 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   6.3872     0.8894   7.181 1.01e-07 ***
trttrtA      -0.2686     1.2578  -0.214    0.832    
trttrtB       1.3430     1.2578   1.068    0.295    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.813 on 27 degrees of freedom
Multiple R-squared:  0.06525,	Adjusted R-squared:  -0.003987 
F-statistic: 0.9424 on 2 and 27 DF,  p-value: 0.4021
```
:::
::::::


## Nice work!

![](https://i.sstatic.net/AFpya.gif){width="800" fig-align="center"}

# Two-way ANOVA

## Two-way ANOVA
Last week, we discussed 1-factor or "1-way" ANOVA. This let us compare the means of 2+ groups and determine whether there was any evidence that one or more groups were different than the others.

. . .

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> For example, is there a difference in the mean number of insects captured among 3 different colored sticky cards placed adjacent to a soybean field.
:::

. . . 

:::box-6-list
Cool! But what about when we have an experiment with [more than 1 treatment factor]{.highlight-tomato} (e.g., temperature and precipitation?)
:::

## Analysis of variance (ANOVA)
**Two-way ANOVA**

. . . 

:::box-6-list
In a factorial design, two (or more) categorical variables are "crossed" with one another (e.g., two levels of temperature and two levels of irrigation)
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> This design, also called a fully-factorial, or full-crossed design, yields 4 total treatment combinations that we *could* analyze in a 1-way ANOVA.
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> However, such an approach only allows us to determine the impact of each treatment independently, and not their combined or interactive effects with one another!
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> Two-way ANOVAs let us specifically model the [interaction]{.highlight-tomato} term that examines whether the effect of one treatment variable varies depending on the level of the other treatment.
:::

## Analysis of variance (ANOVA)
**Two-way ANOVA | The ANOVA table**

| Source            	| *df*         	| SS                	| MS        | F-ratio                    | *P*-value         |
|--------------------	|--------------	|--------------------	|---------	| -------------------------- | ----------------- |
| Factor A          	| $a - 1$      	| (see PES pg. 305) 	| $\frac{SS_{factor A}}{df_{factor A}}$       	| $\frac{MS_A}{MS_{error}}$  |             |
| Factor B          	| $b - 1$      	| (see PES pg. 305) 	| $\frac{SS_{factor B}}{df_{factor B}}$       	| $\frac{MS_B}{MS_{error}}$  |             |
| A x B interaction 	| $(a-1)(b-1)$ 	| (see PES pg. 305) 	| $\frac{SS_{interaction}}{df_{interaction}}$ 	| $\frac{MS_{AB}}{MS_{error}}$ |             |
| Error             	| $ab(n-1)$    	| (see PES pg. 305) 	| $\frac{SS_{error}}{df_{error}}$             	|                            |             |
| Total             	| $abn-1$      	| (see PES pg. 305) 	|                                             	|                            |             |

. . . 

Here, you can test 3 $F$-ratios: two main effects and their interaction. All use the $MS_{error}$ term in the denominator!

# Model diagnostics

## Linear model assumptions
**ANOVA, Linear Models (regression), t-tests, and beyond!**

. . . 

1. Model is correct

. . . 

2. Samples are independent across and within treatments

. . . 

3. Variance is homogeneous among groups (i.e., each group contributes ~ equally to the within group sum of squares; $\sigma_1^2 = \sigma_2^2 = ... = \sigma_k^2$)

. . . 

4. Residuals are normally distributed

. . . 

:::box-6-list
These assumptions are listed from mostest to most important (because none of them are *not* important)
:::

## Linear model assumptions
**Assumption 1: Model is correct**

:::box-6-list
This is the art of statistics! We can plug experimental data into just about any model framework in the computer and have it spit out some stuff for us to interpret. But is it meaningful?
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> Folks tend to look for p-values before they look for anything else. This is a one of the perverse incentives from the publishing rat-race we're all apart of. 
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> This assumption is best addressed through common sense and attention to detail. And...
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> ...conducting your analyses consistent with the manner in which you conduct your experiment/observational studies.
:::

## Linear model assumptions
**Assumption 2: Samples are independent across and within treatments**

:::box-6-list
These details are best sorted at the experimental and study design phase. Recall the discussions we've had about bias, randomization, etc.
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> This assumption is nothing that we can test or visualize to assess; we simply must critique the experimental methods/procedure used to collect our samples. 
:::

. . . 

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> Recall the discussions we've had about bias, randomization, etc. 
:::

## Linear model assumptions
**Assumption 3: Variance is homogenous among groups**

:::box-6-list
Equal variance can be assessed using tests (e.g., Levene's test), but in practice we tend to assess this assumption **visually** using residual plots
:::

## Linear model assumptions
**Assumption 4: Residuals are normally distributed**

:::box-6-list
Till now, we have been simplifying this assumption, saying something like: each treatment is a random sample $Y_{ij} \sim N(\mu_i, \sigma_i^2)$. Technically, this isn't quite correct (but it gets us most of the way there)
:::

. . .

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> We actually care the most about our residual error distribution; that is, we want our model to be "wrong" consistently and have these errors follow a random sample $Y_{ij} \sim N(0, \sigma_i^2)$
:::

##

:::{.center-xy}
**Cool. But how do we actually assess these assumptions in our analyses?** 
:::

## Residual plots
:::box-6-list
For linear models, we can assess many of our assumptions by examining [residual plots]{.highlight-tomato}
:::

. . .

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> A residual plot graphs our residual values, $r_i$ against our fitted model values, $\hat{y}_i$.
:::

. . .

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> If we add up all of our residuals, $\sum_{i=1}^{n} r_i = 0$ and $\sum_{i=1}^{n} r_i^2 = SSError$ aka within-group variance
::: 


. . .

::: indented-text
<i class="fa-solid fa-turn-up fa-rotate-90"></i> We can assess our assumptions of equal variance and normally distributed residuals with a single residual plot!
::: 

## Residual plots
**Ideal residual plots**

:::box-6-list
Ideally, residual plots should look like a random scattering of points surrounding a horizontal line with a y-intercept of 0 (i.e., no difference between fitted value and actual data)
:::

. . .

![](./slide_media/w5/resid-normal.png){width="450" fig-align="center"}


## Residual plots
**Ideal residual plots**

:::box-6-list
We also want to see our [residuals normally distributed]{.highlight-tomato} about $\mu_{d_i} = 0$ - we don't want our model to be systematically over- or under-predicting true values. this would indicate we're missing an important variable from our model
:::

. . .

![](./slide_media/w5/resid-normal-dist.png){height="375" fig-align="center"}


## Residual plots
**Non-linear fit**

:::box-6-list
When residuals are correlated with the fitted values, this is indicative of a non-linear relationship between our predictor and response variable.
:::

. . .

![](./slide_media/w5/resid-nonlinear.png){width="500" fig-align="center"}

## Residual plots
**Non-linear fit**

:::box-6-list
A "U" or inverted "U" shape to our residuals tends to indicate a quadratic rather than a linear relationship between our predictor and response variable.
:::

. . .

![](./slide_media/w5/resid-quadratic.png){width="500" fig-align="center"}

## Residual plots
**Heteroscedasticity**

:::box-6-list
Residual plots displaying an increasing or decreasing funnel of points when plotted against fitted indicate that our nonhomogeneous variance, or [heteroscedasticity]{.highlight-tomato}
:::

. . .

![](./slide_media/w5/resid-hetero.png){width="500" fig-align="center"}

## Residual plots
**Outliers/leverage**

:::box-6-list
Residual plots can also help us evaluate whether certain values may be [outliers]{.highlight-tomato} and exhibiting significant leverage on our fitted models.
:::

. . .

![](./slide_media/w5/resid-outlier.png){height="375" fig-align="center"}